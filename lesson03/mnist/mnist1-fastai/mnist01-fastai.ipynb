{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875bcbdb-b248-454d-8f91-ffc366278ef0",
   "metadata": {},
   "source": [
    "# MNIST Iteration 1 - Training a Fast.AI model\n",
    "\n",
    "After I downloaded the kaggle dataset, I was a bit surprised that it did not contain any \"real\" images, i.e. image files. Instead, the images are stored in a `csv`.file.\n",
    "\n",
    "To get a quick result and a baseline, I decided to switch to the MMIST-dataset provided by Fast.AI for training my first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8befe84-bd03-43c8-a841-365fce78d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a38b5c-b63a-4c76-9de4-bea5ffe9e847",
   "metadata": {},
   "source": [
    "## Downloading the Fast.AI MNIST Dataset\n",
    "\n",
    "Fast.AI has a version of MNIST available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3b62ea-c634-48c9-9616-41b93f118b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c49031a-1d0e-4cf9-826e-03b6381c4e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/chrwittm/.fastai/data/mnist_png')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed133ee4-0b04-4fcf-bd94-8d848cd7758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/chrwittm/.fastai/data/mnist_png/training'),Path('/home/chrwittm/.fastai/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf04a35-bff1-4ab6-8d96-c8f3b411a0c7",
   "metadata": {},
   "source": [
    "As a result, we have a the training dat and the testing data in separate folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ee6f3d-7e38-4b08-ae60-f0e2eae6e2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('/home/chrwittm/.fastai/data/mnist_png/training/4'),Path('/home/chrwittm/.fastai/data/mnist_png/training/7'),Path('/home/chrwittm/.fastai/data/mnist_png/training/9'),Path('/home/chrwittm/.fastai/data/mnist_png/training/5'),Path('/home/chrwittm/.fastai/data/mnist_png/training/8'),Path('/home/chrwittm/.fastai/data/mnist_png/training/0'),Path('/home/chrwittm/.fastai/data/mnist_png/training/2'),Path('/home/chrwittm/.fastai/data/mnist_png/training/1'),Path('/home/chrwittm/.fastai/data/mnist_png/training/6'),Path('/home/chrwittm/.fastai/data/mnist_png/training/3')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'training').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad7ea1f-939f-4c67-a059-fa76036b4d60",
   "metadata": {},
   "source": [
    "In the training folder, there are folders for the `png`-pictures of each number, which we can use for the lables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08367fc-b131-4a40-a1be-8d0cc054bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (path/'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd3da7f-a640-4306-926c-38c3f372ddba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/chrwittm/.fastai/data/mnist_png/training')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790fdcb2-104a-41a5-8331-3280332d7bf0",
   "metadata": {},
   "source": [
    "## Creating a quick model\n",
    "\n",
    "With this dataset, let's create a quick model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1198fc1-a7c0-463b-a4e4-8168d5a12d26",
   "metadata": {},
   "source": [
    "Introducing a new variable `do_learn` which needs to be set to `True` for the training to actually happen. - This is just for efficiency, and we can always use the `export.pkl` for making the predictions once the training has been completed once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc7532d-2360-4279-aa78-87e631016a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_learn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8d03d9-6fbb-407e-990c-a4ad7aee6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_learn:\n",
    "    mnist1 = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock), \n",
    "        get_items=get_image_files, \n",
    "        splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "        get_y=parent_label,\n",
    "        #item_tfms=[Resize(192, method='squish')]\n",
    "    )\n",
    "    dls = mnist1.dataloaders(path, bs=32)\n",
    "    dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec1ac690-e3da-4040-aec3-cd40fd53e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_learn:\n",
    "    learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "    learn.fine_tune(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9b25653-b7fa-49c9-b622-3dbf862c9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_learn:\n",
    "    learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd85cfdc-c2a1-4ca8-8dfe-0aa9f9d213a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_learn == False:\n",
    "    learn = load_learner('export.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050aaac-d05a-41d9-b250-3d5ea5820711",
   "metadata": {},
   "source": [
    "Independent on how the variable `do_learn` was set, we always have a learner now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bded2e3-a8c3-4784-900e-6632dea9322d",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "Running the training on my local machine took about 40 minutes:\n",
    "\n",
    "![CPU](benchmark-cpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331a72dc-f2d4-437f-821b-3a556fc583a5",
   "metadata": {},
   "source": [
    "Running on a free Paperspace GPU-server took about 5 minutes, so roughly an order of magnitude:\n",
    "\n",
    "![GPU](benchmark-free-gpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b14b7-9ed0-4eca-9cfa-20d2fa1e1f71",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "\n",
    "Let's use the `learner` to make some predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5ef2dfc-e776-4d3f-8cc7-d5437e247e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner('export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b5da5e9-1ca0-4a69-8072-5f6082387fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/chrwittm/.fastai/data/mnist_png/training')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8124488c-461a-4cab-ac35-62cfcc406133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB8ElEQVR4nO3Su4vqQBQHYMfCgKQTCyGW2i0EA2JAsEwRy8Q/RLDQSrSwsjCdVUAIVjaxsxAfQcHGdJYaRDGFD7ASzjFbhCt7110f64Xb7K+bmZOPkzPj8fzm/4bjOFVVEVFV1Vgs9g9ElmV3ux38yXa7fVWMx+PL5RIRAWC/39u2DQA8z/t8vp9wfr8/mUwuFgsAcNHJZCJJkrssFArXn3jvovV6vdfrMQxz2YnFYjRN9/t9j8fz9vb2NMpxnCiKhBBCyGAwyOVyhJDNZjOdThVF8Xq9hJC7bf2VjzfTbrdpmhZFMZ/PB4NBtwARj8fjE88gGo1qmoaItm2bpilJ0nWNO2JN0x4SKYrSdR0ADoeDIAiBQODjTD+hw+HwIZTnefevU6nUjbLn0NFohIjdbvd2meM4iGgYxqf9L24/nU6zLOs4jq7rt9Hz+ew4jmma99uUZRkA1ut1KBT6roaiqEqlgoidToem6UfR+Xx+QyyXywBgWZYgCPfFC1qr1b48ZVlW0zQAaLVaD3FuMpkMIlqWdX2UzWZ3ux0iNhqNJ8RLp6fTSVEUlmXD4bAsy7quW5aFiPP5vNlsJhKJn6BuVqvVbDa7LA3DKJVKz3FuGIYZj8eu4j5vALBt+7spP5pQKFQsFi9otVqNRCIvib95Me/8RUrNjUX6NgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "PILImage mode=RGB size=28x28"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = PILImage.create(path/'0/1.png')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2be5fcda-dda4-4def-b26f-fa93023ad30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.dls.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05369962-1f6d-49e7-be11-77a4f861dd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('0',\n",
       " TensorBase(0),\n",
       " TensorBase([9.9875e-01, 3.0521e-04, 1.0101e-04, 1.0142e-04, 8.4972e-05,\n",
       "             1.4241e-05, 4.1763e-06, 1.7488e-04, 2.6674e-04, 2.0044e-04]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5064558-f1db-40c2-a3fd-4cb2ffd926ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img):\n",
    "    pred,pred_idx,probs = learn.predict(img)\n",
    "    return dict(zip(learn.dls.vocab, map(float, probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb10bb5d-09ef-47ce-925e-531f4311de56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'0': 0.9987469911575317,\n",
       " '1': 0.0003052067186217755,\n",
       " '2': 0.00010101054795086384,\n",
       " '3': 0.00010141720849787816,\n",
       " '4': 8.497152157360688e-05,\n",
       " '5': 1.4241136341297533e-05,\n",
       " '6': 4.176294623903232e-06,\n",
       " '7': 0.00017488478624727577,\n",
       " '8': 0.0002667366643436253,\n",
       " '9': 0.00020043794938828796}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_image(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134d3716-e9ec-4303-b79b-5ef68f6418ad",
   "metadata": {},
   "source": [
    "I could run a lot more predictions, but let's move on to the next task, i.e. working with the kaggle data to make a submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
