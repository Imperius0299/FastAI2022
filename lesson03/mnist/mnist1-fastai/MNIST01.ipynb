{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "875bcbdb-b248-454d-8f91-ffc366278ef0",
   "metadata": {},
   "source": [
    "# MNIST, the \"Hello World\" of Computer Vision\n",
    "\n",
    "After Cat vs. Dog, this is the next challenge for me in computer vision. Building on [chaper 4](https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb) of the book, I would like to implement the whole [MNIST](https://en.wikipedia.org/wiki/MNIST_database), as recommended as futher research and as also avaiblable as a [Kaggle competition](https://www.kaggle.com/competitions/digit-recognizer/data).\n",
    "\n",
    "Again, the way to implement will be the following (like with the [Titanic-Challenge](https://chrwittm.github.io/posts/2022-11-05-kaggle-titanic/):\n",
    "* Implement a Fast.AI version to get a feeling of the data and also to get a result quickly\n",
    "* Implement a from-scrach version for additonal learnings and insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8befe84-bd03-43c8-a841-365fce78d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948d5bb-2eb3-467b-b762-24ccf91a5244",
   "metadata": {},
   "source": [
    "## Downloading the dataset\n",
    "\n",
    "### From Kaggle\n",
    "\n",
    "Let's download the dataset from Kaggle. Uncomment the next line of you do not have it on your machine yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c3f2a5-4e00-42d5-8389-366371a602b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions download -c digit-recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c97bb0-a488-4ea1-8246-3ffa6e7c8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip digit-recognizer.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cdb241-e4ce-44bd-8877-0cf541c23dc2",
   "metadata": {},
   "source": [
    "As presented in the book, let's do all the file manipulation directly from the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b254f3-8ab3-4a27-9c9a-2fd6ed563d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('.')\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5bbfbbc-f480-4690-b5cb-c98f912dc6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('benchmark-cpu.png'),Path('MNIST01.ipynb'),Path('.ipynb_checkpoints')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee8b4b9-bf9e-4ca9-ab80-da1ff79e5f10",
   "metadata": {},
   "source": [
    "This is a bit of a surprise that we get a csv file for the images...\n",
    "Need to construct an image...\n",
    "Also rearanging the images seems to be a good exercise..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a38b5c-b63a-4c76-9de4-bea5ffe9e847",
   "metadata": {},
   "source": [
    "### From Fast.AI\n",
    "\n",
    "As a comparison, let's quickly download the Fast.AI version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c3b62ea-c634-48c9-9616-41b93f118b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.03% [15687680/15683414 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed133ee4-0b04-4fcf-bd94-8d848cd7758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/root/.fastai/data/mnist_png/training'),Path('/root/.fastai/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd67940-c581-4dab-b203-02bca913c035",
   "metadata": {},
   "source": [
    "Next: Start with the Fast.AI version, because that will yield quicker results, taking the images and training a model should be no overly difficult...\n",
    "\n",
    "Afterwards: Use the kaggle data to convert it and run the same thing\n",
    "\n",
    "Afterwards: Train your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b45fb-ddd2-4049-8fe0-28dbf2c249fa",
   "metadata": {},
   "source": [
    "## Creating a quick model\n",
    "\n",
    "with this dataset, let's create a qick model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c49031a-1d0e-4cf9-826e-03b6381c4e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/root/.fastai/data/mnist_png')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "155a65d5-20f9-4b94-8262-ab7978f93fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/root/.fastai/data/mnist_png/training')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ee6f3d-7e38-4b08-ae60-f0e2eae6e2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('/root/.fastai/data/mnist_png/training/8'),Path('/root/.fastai/data/mnist_png/training/3'),Path('/root/.fastai/data/mnist_png/training/9'),Path('/root/.fastai/data/mnist_png/training/2'),Path('/root/.fastai/data/mnist_png/training/4'),Path('/root/.fastai/data/mnist_png/training/1'),Path('/root/.fastai/data/mnist_png/training/0'),Path('/root/.fastai/data/mnist_png/training/5'),Path('/root/.fastai/data/mnist_png/training/7'),Path('/root/.fastai/data/mnist_png/training/6')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'training').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d08367fc-b131-4a40-a1be-8d0cc054bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (path/'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bd3da7f-a640-4306-926c-38c3f372ddba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/root/.fastai/data/mnist_png/training')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7532d-2360-4279-aa78-87e631016a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_learn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf8d03d9-6fbb-407e-990c-a4ad7aee6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_learn:\n",
    "    mnist1 = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock), \n",
    "        get_items=get_image_files, \n",
    "        splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "        get_y=parent_label,\n",
    "        #item_tfms=[Resize(192, method='squish')]\n",
    "    )\n",
    "    dls = mnist1.dataloaders(path, bs=32)\n",
    "    dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec1ac690-e3da-4040-aec3-cd40fd53e692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77bd9466c3c4c71b6988f8bc03a5d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.770205</td>\n",
       "      <td>0.482641</td>\n",
       "      <td>0.151917</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.159833</td>\n",
       "      <td>0.087284</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.083694</td>\n",
       "      <td>0.046194</td>\n",
       "      <td>0.013167</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if do_learn:\n",
    "    learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "    learn.fine_tune(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9b25653-b7fa-49c9-b622-3dbf862c9155",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'export'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m learn:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'export'"
     ]
    }
   ],
   "source": [
    "if do_learn:\n",
    "    learn.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bded2e3-a8c3-4784-900e-6632dea9322d",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "Running the training on my local machine took about 40 minutes:\n",
    "\n",
    "![CPU](benchmark-cpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331a72dc-f2d4-437f-821b-3a556fc583a5",
   "metadata": {},
   "source": [
    "Running on a free Paperspace GPU-server took about 5 minutes, so roughly an order of magnitude:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
