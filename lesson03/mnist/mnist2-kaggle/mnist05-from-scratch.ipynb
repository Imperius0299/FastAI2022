{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b5da4fc-9389-4ecb-b979-5ef8ab136f01",
   "metadata": {},
   "source": [
    "# MNIST from scratch\n",
    "\n",
    "In this notebook, I am implementing a model for solving the MNIST competition from scratch. [Chapter 4](https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb) of the book is my guide, and I will implement this in analogy.\n",
    "\n",
    "I skip over the exercise to create a model based on the average pixel values of each digit, instead, I jump straight to the linear model / neural net. I added text where I felt that it improved my understanding of what is going on, or where I felt that the book was too compact. In any case I recommend also reading along in the book, as I do not intend to re-write the chapter in this notebook. For easy reference, I kept the main headings the same as in the book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc539e8-bf48-4708-86b7-6c165c1b5798",
   "metadata": {},
   "source": [
    "## Converting the Data\n",
    "\n",
    "The first task is to convert the `csv`-files into tensors so that we can work with it.\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b728d6ae-a276-44b9-b125-9f0bb264ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa195540-c839-4f15-b071-71c91804fb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b1f2f-29bf-42f6-9d4c-842bebb3ab06",
   "metadata": {},
   "source": [
    "For the initial phases of writing this notebook, I limited the number of images to a smaller size, so that things were easier visualize, easier to analyze etc. As it turned out, this was useful for the data conversion and for creating the loss function, but afterwards I removed the limit. For historic reason, I leave it in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423f9a99-a47a-4a1a-8c2c-189ed4893fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e191221-f08e-49be-b8af-a5ab87758d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if limit > 0:\n",
    "    train = train[:limit]\n",
    "\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75cbf0-9291-4915-89ed-9b044e7d060f",
   "metadata": {},
   "source": [
    "Let's split the data into a training set and a validation set. Just to state the obvious: We cannot use the test set as a validation set because it is not labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc5d5c5-befe-4288-a0a3-b499271671f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 8400)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_percentage = 0.8\n",
    "split_index = int(len(train) * train_percentage)\n",
    "split_index\n",
    "valid = train[split_index:]\n",
    "train = train[:split_index]\n",
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfdbd58-51e7-4b8d-a6c7-480b7ef9d2a0",
   "metadata": {},
   "source": [
    "The independent variables `x` are the images (i.e. the pixels of each 28x28 image) and the dependent variable `y`are the lables.\n",
    "\n",
    "The images reside in the second to the last column of the training dataframe.\n",
    "\n",
    "The labels reside in the first column of the training dataframe.\n",
    "\n",
    "For converting the data, the following magic is contained in the next line of code:\n",
    "\n",
    "* `pd.DataFrame.values`, i.e. the `.values` \"returns a Numpy representation of the DataFrame\" (see `pd.DataFrame.values?`)\n",
    "* to normalize the pixel values to values between 0 and 1 I divided them by 255 (while writing this up, I am actually not sure if that is needed, but somehow it feels like common practice to do it...)\n",
    "* to avoid type conflicts all elements are converted to floats by adding `.float()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27806925-8be0-4bbd-9090-8053e493abfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.tensor((train.iloc[:,1:].values)/255).float()\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "868f4d57-0ba7-41cc-8cf9-319d37fcc4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33600, 784]), torch.Size([33600, 784]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.size(), train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5e64c-439a-4f16-a2d1-5a322e130eef",
   "metadata": {},
   "source": [
    "Doing the same for the variables, the dependent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c535612-e556-4b3c-a816-25e5697941e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1.,  ..., 0., 2., 2.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = torch.tensor(train.iloc[:,0].values).float()\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d46a98-8bcc-4dbc-ace8-ac74794cf228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33600]), torch.Size([33600]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.size(), train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15798f-a7b0-4119-8c77-327983676d91",
   "metadata": {},
   "source": [
    "This  looks slightly different in the book... It turns out, we need to convert this 1D tensor into a 2D tensor so that we can use it in our calculations.\n",
    "\n",
    "The line of code below is inspired by <https://discuss.pytorch.org/t/convert-1d-tensor-to-2d-tensor/5599/4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41c5dba9-311a-4a79-9288-d9ed9077ae24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [4.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train_y.view(len(train_y), 1)\n",
    "train_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56356ab5-e6ac-4f62-aa3f-5dbf24f252af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33600, 1]), torch.Size([33600, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.size(), train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386fba38-43a4-46e2-98c2-f266981c6849",
   "metadata": {},
   "source": [
    "Now the result looks like in the book :)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058b790-9c54-4f82-aea9-7b127dc502ba",
   "metadata": {},
   "source": [
    "Finally, let's create a dataset, i.e. a collection of tuples `(x,y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e47c3ae-13ec-43a5-a5f2-875a5a27809e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c4904-ea5a-4ae5-8056-02bc24ef4b14",
   "metadata": {},
   "source": [
    "Let's repeat for the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c68ba96-707a-4b1e-a4de-e8844276a7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8400, 784]), torch.Size([8400, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = torch.tensor((valid.iloc[:,1:].values/255)).float()\n",
    "valid_y = torch.tensor(valid.iloc[:,0].values).float()\n",
    "valid_y = valid_y.view(len(valid_y), 1)\n",
    "valid_dset = list(zip(valid_x,valid_y))\n",
    "valid_x.shape, valid_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd15d61-6d5d-4559-8226-e1d878305970",
   "metadata": {},
   "source": [
    "## The Loss Function\n",
    "\n",
    "### Initializing the parameters\n",
    "\n",
    "To get started working on the loss function, we need to initialize the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f5e74d1-afe7-4558-bd8a-de871d23c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33eade56-975d-4ac8-87fe-21b86faa8bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9063],\n",
       "        [-0.6531],\n",
       "        [-0.0431],\n",
       "        [-3.2855],\n",
       "        [ 0.4129]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = init_params((28*28,1))\n",
    "weights[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d09ae04a-b21e-45ed-93ff-eb2809971534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d7836f1-5d52-4225-b63e-09b75d8738e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2507], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = init_params(1)\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c010d4b-7be4-4c98-9d68-6d8ea4d2fb55",
   "metadata": {},
   "source": [
    "### Short excursion on matrix multiplication\n",
    "\n",
    "Calculating the prediction for the first element:\n",
    "\n",
    "> Note: `weights.T` is the transposed tensor. For doing this \"normal\" multiplication the tensor of the individual image needs to be \"flipped\". When using the matrix multiplication, the regular version of our tensor is used. As you can see the 2 following cells return the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc861771-4b2d-4996-afd4-76a72e36f7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.5514], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x[0]*weights.T).sum() + bias # T is the transposed tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94bdfedb-a72c-48e6-be13-9e8a3b28c96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.5514], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x[0]@weights).sum() + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9128c88b-1f1e-4241-80ec-3fe15d028ffe",
   "metadata": {},
   "source": [
    "Revisiting matrix multiplication: As described on more detail in my blog post on [matrix multiplication](https://chrwittm.github.io/posts/2022-10-28-matrix-multiplication/), the number of columns of matrix $A$ need to match the number of lines of matrix $B$:\n",
    "\n",
    "![Matrix dimensions](https://chrwittm.github.io/posts/2022-10-28-matrix-multiplication/khan-matrix-dimensions.png)\n",
    "\n",
    "_Illustration [by Khan Academy CC BY-NC-SA 3.0 US](https://www.khanacademy.org/)_\n",
    "_[Note](https://support.khanacademy.org/hc/en-us/articles/202262954-Can-I-use-Khan-Academy-s-videos-name-materials-links-in-my-project-): All Khan Academy content is available for free at (www.khanacademy.org)_\n",
    "\n",
    "We can nicely see this when looking at the shape of our tensors (note that the values `784` in the output of the second line are next to each other):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2559d060-b3c2-46df-bec3-ac19419ae249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This does not work: torch.Size([784]), torch.Size([1, 784])\n",
      "This works: torch.Size([784]), torch.Size([784, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f'This does not work: {train_x[0].shape}, {weights.T.shape}')\n",
    "print(f'This works: {train_x[0].shape}, {weights.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0e5e7-7e0b-4f6e-9f60-708492c4d5dc",
   "metadata": {},
   "source": [
    "Same for the whole matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21483dd5-22cb-42c1-83bd-43c23504426f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This does not work: torch.Size([33600, 784]), torch.Size([1, 784])\n",
      "This works: torch.Size([33600, 784]), torch.Size([784, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f'This does not work: {train_x.shape}, {weights.T.shape}')\n",
    "print(f'This works: {train_x.shape}, {weights.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a286611-015c-4f6e-8c72-5f1bcbfa036f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33600, 784]), torch.Size([1, 784]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, weights.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ca369-d69c-4221-b0f6-690e5963a601",
   "metadata": {},
   "source": [
    "### Calculating the predictions (forward pass)\n",
    "\n",
    "In our current simple model, we matrix multiply the parameters with the weights (+ bias).\n",
    "\n",
    "Let's wrap that in a function, as suggested in the book. \n",
    "\n",
    "> Personal Note 1: I do not really like the global usage of the weight and bias in the function...\n",
    "\n",
    "> Personal Note 2: Is it actually important to wrap this in a function because otherwise it cannot calculate the gradients?\n",
    "\n",
    "Let's Calculate the predictions for the whole training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "326262d7-477f-42ed-b9c3-dbd7851b5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(xb): return xb@weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cd3e9a9-dbd9-42fc-a4ae-8bf3beb4b303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.5514],\n",
       "        [-1.4782],\n",
       "        [10.9867],\n",
       "        [ 0.3375],\n",
       "        [-0.5475]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1 = linear1(train_x)\n",
    "preds1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88f7a5-e438-4b5c-9e38-c91306e09d3e",
   "metadata": {},
   "source": [
    "Notice: The first element of the tensor is the same as the value we calculated above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb74597-d7a6-4950-91e7-214336446caf",
   "metadata": {},
   "source": [
    "Let's compare the predictions with the actual labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "847cb584-e70c-4397-b347-43b31cf6b5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.],\n",
       "        [-1.],\n",
       "        [11.],\n",
       "        [ 0.],\n",
       "        [-1.]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1.round()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ed50570-8b06-4c38-9144-294f4a1bed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [4.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "063f6541-9ca8-4482-825e-f70771b54b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = preds1.round() == train_y\n",
    "corrects[:5] # all wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f374dab3-c1e8-4707-b808-cb6ff78b6f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0317)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6b32bf-534c-4e83-8472-5b22bc27faf1",
   "metadata": {},
   "source": [
    "As it turns out, the vast majority of the predictions is wrong. This is not really surprising, because we randomly initialized the parameters.\n",
    "\n",
    "> Note: Normalizing the pixel values to values between 0 and 1 sure helped this result. Without the normalization, we would have zero corrects.\n",
    "\n",
    "Actually, I was struggling with the fact that there are any correct values because essentially, everything is this calculation (so far) is random. I was also struggling with the fact that you could simply define which results of the net represent correct values. (At this point in the book, the define that a `0` means a `3` and a `1` means a `7`.) And essentially, you can make up anything as long as it is consistent, because the model will learn these values because that is what gradient descent will descent to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e02325-aae5-4840-a922-2deef21c979d",
   "metadata": {},
   "source": [
    "### Defining the loss function\n",
    "\n",
    "Now we can define the loss function: Let's use the mean squared error between the predictions and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a84efd66-ab19-4171-acd8-f1344a259c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(preds, targets):\n",
    "    return ((preds-targets)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03291f13-0030-4326-87d2-f33d3abb16f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(147.2167, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1 = mnist_loss(preds1, train_y)\n",
    "loss1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c893cb3-d943-48c8-bc85-e238de59518f",
   "metadata": {},
   "source": [
    "### Manual backpropagation\n",
    "\n",
    "After having calculated the loss, we can do a bit of backpropagation to see if we are on the right track.\n",
    "\n",
    "Calling `.backward()` will calculate the gradients, i.e. the effect that each individual pixel value has on the loss function, i.e. how the loss changes it we adjust the value of one pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46d06254-7b73-48a7-ab1e-a2c4cdbb5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e55a8b-9e67-46ff-91c7-c497ad3fd654",
   "metadata": {},
   "source": [
    "Adjusting the weights with a learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26767532-d997-4127-8fd4-f686cfe23fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = weights.grad * 0.001 #not sure about this one, I think this is an error, because I do not adjust the weight, but replace them\n",
    "\n",
    "with torch.no_grad(): weights -= weights.grad*0.01 # this is better: update parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e510372-3bcb-4db3-b33e-0e0d9a91a17c",
   "metadata": {},
   "source": [
    "Doing the forward pass again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27b963f5-4f26-4127-9637-bc922c76bc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0176],\n",
       "        [ 6.6123],\n",
       "        [14.0653],\n",
       "        [ 2.9795],\n",
       "        [ 7.9765]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds2 = (train_x@weights + bias)\n",
    "preds2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fb0cf5e-4e41-4d27-a582-7ef9d05e2b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(84.9808, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2 = mnist_loss(preds2, train_y)\n",
    "loss2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb819ded-3b04-4f8f-9d46-7f395057f829",
   "metadata": {},
   "source": [
    "The loss went down :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51a8acb6-c51b-4b26-98fd-28478528eb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0443)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = preds2.round() == train_y\n",
    "corrects.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e2f74-2d81-4b3f-985a-a89ca1bc2768",
   "metadata": {},
   "source": [
    "Additionally, we have more corrects, so we did one optimization step, and it looks like it actually worked :).\n",
    "\n",
    "But as described in the book, and also in some previous notebooks we also have to care about initializing gradients, so this would get pretty tedious.\n",
    "\n",
    "Additionally, you would usually not use all the parameters for a training run, but instead, you would use mini-batches for training - which the dataloaders will do for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a522eea-80fc-4596-beab-49aecf02e1a3",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "The following code, taken from the book, is quite compact, but actually pretty straight forward.\n",
    "\n",
    "The following function, calculates the forward pass by calling `model(xb)`: In our context this actually `linear1(train_x)` because we pass `linear1` as the `model` and `train_x` as `xb`.\n",
    "\n",
    "Afterward id calculates the loss and does the backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30a2fb58-e7a4-434e-a3ed-5588cb438f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbfb19e-d6fd-4956-9603-c8601fadc50c",
   "metadata": {},
   "source": [
    "For training a whole epoch (i.e. running over all the training data once), the following function iterates over the dataset stored in the dataloaders, calculated the gradients, updates the parameters and initializes the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f48c8b0-7f82-4469-ade5-7bf66389866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a44ce-a981-4cf8-b37c-8336d58ccb76",
   "metadata": {},
   "source": [
    "The following function is my own implementation of determining the batch accuracy: A digit is correctly predicted if the rounding the predicted values reveals the digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8504886c-eccf-44cb-b6ff-6de85a61352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.round()\n",
    "    correct = preds == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970cf33-23c7-44e6-bcc8-850738770ec3",
   "metadata": {},
   "source": [
    "To validate an epoch, i.e. after having performed the training, i.e. the updates of the parameters, the following function iterates over the validation dataloaders, runs the forward pass (`model(xb)`) and compares that to the validation labels `yb`. The accuracy is returned as the`round`ed `mean()` of the individual tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92883a6e-0766-4962-8227-5b0574a8379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f37674-ef91-4d06-8185-d552fa66f676",
   "metadata": {},
   "source": [
    "### Reinitialize parameters\n",
    "\n",
    "Let's start over again with some fresh set of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09dcb6e4-d811-4f7e-a2f0-5d2ac83ee70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2447584a-461c-4cbd-a75b-1c1e7df855e7",
   "metadata": {},
   "source": [
    "Using a dataloaders for managing the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d697221-b2fb-4505-b9df-a4f3110fde24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4f4014-9be9-4d8e-bb8d-d9b48a474d60",
   "metadata": {},
   "source": [
    "The same for the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16d4700e-3180-4715-bec4-8e792ac4a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beeebf6-85ae-46d7-8a78-8d115f0b98e6",
   "metadata": {},
   "source": [
    "Without any training, we can still validate our parameters, which show some random corrects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "369f2c87-a220-4cb3-aa25-eb745adc7ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0449"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = weights,bias\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6509f96-9c81-497e-b4b2-e297b075e432",
   "metadata": {},
   "source": [
    "Now, let's train one epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76da06a7-bf96-40c1-8227-56560d567e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.097"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.005\n",
    "params = weights,bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebca7a83-b9d7-4f04-b10a-7ee82d5cf3c6",
   "metadata": {},
   "source": [
    "That is a good improvement :)\n",
    "\n",
    "> Note: One big learning here was that setting the training rate is SUPER important. The book uses a learning rate of `1`, but this would result in disaster for this model. We would always have zero corrects.\n",
    "\n",
    "Let's do 20 more epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3cb287b-3e1b-412d-bd22-ac97f2b37f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1103 0.1209 0.1289 0.1332 0.1354 0.1352 0.1383 0.1433 0.1437 0.1485 0.153 0.1541 0.1585 0.1596 0.1614 0.1627 0.1644 0.1648 0.1668 0.1692 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3496e184-f574-44b7-bef9-73e04334ead3",
   "metadata": {},
   "source": [
    "The results are not yet particularly great, but we can see some improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2965f-518d-4fe6-84fb-3581f2dcc49f",
   "metadata": {},
   "source": [
    "## Creating an Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2007128-830e-4acc-91c1-ba72882d127d",
   "metadata": {},
   "source": [
    "Let's re-implement what we did before with a Pytorch linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7da40b72-de8e-4770-83c8-fe4903c584ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(28*28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0a6115-3e1d-4374-93a7-3aa15faebdc3",
   "metadata": {},
   "source": [
    "A new set of weights and biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0497d8f8-8084-42f9-b55f-44bf9f4b4b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b = linear_model.parameters()\n",
    "w.shape,b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a3691f-52ae-4220-a327-0de0beeed9a6",
   "metadata": {},
   "source": [
    "The following is taken from the book (again), and we can see that it essentially contains the same code as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e644f00-5269-4111-be18-72d29822c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54e38bb6-57e6-4a39-8620-6fb188b6242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim(linear_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83c51210-76c5-4773-bf20-5010b762e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d32af-e3ee-4af4-8aad-f3899a343ab0",
   "metadata": {},
   "source": [
    "This is our starting point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8cf1e2ec-06a6-47e4-97c0-62730794e37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1003"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007df744-da01-4698-a3d4-567c94bc0fe8",
   "metadata": {},
   "source": [
    "Let's train for 20 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4eedc2db-3163-46de-abe6-d0ff4e76172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "20df6cb1-9544-4fcf-ad1b-af5bae96ca7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1769 0.193 0.202 0.205 0.2077 0.2074 0.2094 0.2121 0.2127 0.2138 0.2134 0.2139 0.2139 0.2148 0.215 0.215 0.2145 0.2151 0.2155 0.2165 "
     ]
    }
   ],
   "source": [
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f552d0a5-2d01-459a-bd90-1a4282e39808",
   "metadata": {},
   "source": [
    "To be honest I am not quite sure, why this is performing a bit better..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac390a-1219-4d55-be7d-4223c7668a4e",
   "metadata": {},
   "source": [
    "Re-doing the same thing with a little bit more of Fast.AI magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffecc53c-fe86-46f5-8a29-69314d114694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1774 0.1933 0.2039 0.2065 0.2095 0.2085 0.2107 0.2116 0.2124 0.2121 0.2133 0.2145 0.2141 0.2167 0.2162 0.2162 0.217 0.2158 0.215 0.216 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b10e69-2dcf-42b7-b0a2-9990ebc5462e",
   "metadata": {},
   "source": [
    "And now we are ready to use a learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3e60778-3902-4356-a114-2388cec803e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dd8b0cc-8410-4745-a41a-d0c67907986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ffe81c03-05ec-4031-a8cc-c7ee06bdbad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.848422</td>\n",
       "      <td>4.484610</td>\n",
       "      <td>0.172024</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.280970</td>\n",
       "      <td>4.180988</td>\n",
       "      <td>0.193810</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.057806</td>\n",
       "      <td>4.017156</td>\n",
       "      <td>0.201429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.920729</td>\n",
       "      <td>3.901211</td>\n",
       "      <td>0.204881</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.820063</td>\n",
       "      <td>3.811138</td>\n",
       "      <td>0.207738</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.740935</td>\n",
       "      <td>3.738425</td>\n",
       "      <td>0.209405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.676762</td>\n",
       "      <td>3.678550</td>\n",
       "      <td>0.211071</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.623770</td>\n",
       "      <td>3.628623</td>\n",
       "      <td>0.211429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.579461</td>\n",
       "      <td>3.586605</td>\n",
       "      <td>0.212024</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.542054</td>\n",
       "      <td>3.550979</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf8d93-3b97-4f79-bc7a-76f8e2aa67ed",
   "metadata": {},
   "source": [
    "## Adding a Non-linearity\n",
    "\n",
    "Let's create a basic neural net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9df24b55-47fe-4c9a-a288-bb203d8f1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_net(xb): \n",
    "    res = xb@w1 + b1\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2120cd4-a1e3-49ec-8e02-07121ec94c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = init_params((28*28,30))\n",
    "b1 = init_params(30)\n",
    "w2 = init_params((30,1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5febbaec-c24f-42a5-8c38-bb1b0220628f",
   "metadata": {},
   "source": [
    "As it turns out, we can define the same also like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ff61891-0550-4e8d-aff7-1cff7d1ec28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f45beca-e980-4fac-b42a-6f23d6940508",
   "metadata": {},
   "source": [
    "Let's train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f5e6bc59-9bcd-496e-8d44-581735c28e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8bfbc46c-7155-4f02-9283-ad19a5bd7ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.307751</td>\n",
       "      <td>3.880059</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.544580</td>\n",
       "      <td>3.287405</td>\n",
       "      <td>0.246786</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.084344</td>\n",
       "      <td>2.799699</td>\n",
       "      <td>0.289167</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.647977</td>\n",
       "      <td>2.399291</td>\n",
       "      <td>0.329286</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.318112</td>\n",
       "      <td>2.133533</td>\n",
       "      <td>0.360476</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.069795</td>\n",
       "      <td>1.933588</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.914878</td>\n",
       "      <td>1.806098</td>\n",
       "      <td>0.393810</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.787905</td>\n",
       "      <td>1.700211</td>\n",
       "      <td>0.407976</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.692105</td>\n",
       "      <td>1.620444</td>\n",
       "      <td>0.417500</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.597911</td>\n",
       "      <td>1.551217</td>\n",
       "      <td>0.423571</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.508233</td>\n",
       "      <td>1.497813</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.447650</td>\n",
       "      <td>1.454423</td>\n",
       "      <td>0.433571</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.405559</td>\n",
       "      <td>1.459670</td>\n",
       "      <td>0.432024</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.338778</td>\n",
       "      <td>1.370754</td>\n",
       "      <td>0.448214</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.302681</td>\n",
       "      <td>1.338846</td>\n",
       "      <td>0.453929</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.270121</td>\n",
       "      <td>1.311398</td>\n",
       "      <td>0.456548</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.252333</td>\n",
       "      <td>1.317399</td>\n",
       "      <td>0.454881</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.209726</td>\n",
       "      <td>1.262745</td>\n",
       "      <td>0.469643</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.188369</td>\n",
       "      <td>1.248304</td>\n",
       "      <td>0.468571</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.204803</td>\n",
       "      <td>1.231389</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.176328</td>\n",
       "      <td>1.519856</td>\n",
       "      <td>0.372619</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.117930</td>\n",
       "      <td>1.304670</td>\n",
       "      <td>0.441071</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.130286</td>\n",
       "      <td>1.278065</td>\n",
       "      <td>0.444167</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.155299</td>\n",
       "      <td>1.178892</td>\n",
       "      <td>0.485119</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.076728</td>\n",
       "      <td>1.154959</td>\n",
       "      <td>0.489167</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.051877</td>\n",
       "      <td>1.151218</td>\n",
       "      <td>0.486071</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.098959</td>\n",
       "      <td>1.153445</td>\n",
       "      <td>0.490714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.057566</td>\n",
       "      <td>1.422913</td>\n",
       "      <td>0.386071</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.074026</td>\n",
       "      <td>1.154470</td>\n",
       "      <td>0.483929</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.072201</td>\n",
       "      <td>1.110832</td>\n",
       "      <td>0.504881</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.993771</td>\n",
       "      <td>1.098962</td>\n",
       "      <td>0.506786</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.000145</td>\n",
       "      <td>1.330165</td>\n",
       "      <td>0.408810</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.027271</td>\n",
       "      <td>1.116632</td>\n",
       "      <td>0.493095</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.019101</td>\n",
       "      <td>1.101917</td>\n",
       "      <td>0.502381</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.967934</td>\n",
       "      <td>1.255576</td>\n",
       "      <td>0.426071</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.989026</td>\n",
       "      <td>1.097049</td>\n",
       "      <td>0.499643</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.984919</td>\n",
       "      <td>1.088737</td>\n",
       "      <td>0.505357</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.948224</td>\n",
       "      <td>1.155332</td>\n",
       "      <td>0.462381</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.956412</td>\n",
       "      <td>1.073192</td>\n",
       "      <td>0.504286</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.968373</td>\n",
       "      <td>1.050957</td>\n",
       "      <td>0.519167</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c622626-8c4d-4142-ba99-39417f9e1bd3",
   "metadata": {},
   "source": [
    "As it turns out, it performs a lot better than our linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda410d-9b20-4dd1-961f-bbd383508ccf",
   "metadata": {},
   "source": [
    "## Going Deeper\n",
    "\n",
    "I wanted to see how adjusting the layout of the network can change the network performance, both in runtime and it accuracy.\n",
    "\n",
    "Here is a network with 3 layers. Notice that you have to make sure that the number of output parameters of a layer need to match the number of input parameters of the next layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "897189af-5264-4856-a549-67605862f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net2 = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "748e8322-ee2d-4673-a44d-9bf245f3bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net2, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e33dc6f0-b642-451e-8ff1-bb6f56ef0bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.297549</td>\n",
       "      <td>3.415897</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.281935</td>\n",
       "      <td>2.690592</td>\n",
       "      <td>0.302619</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.513027</td>\n",
       "      <td>2.102891</td>\n",
       "      <td>0.385357</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.984050</td>\n",
       "      <td>1.785641</td>\n",
       "      <td>0.407976</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.703177</td>\n",
       "      <td>1.586349</td>\n",
       "      <td>0.441310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.549266</td>\n",
       "      <td>1.455132</td>\n",
       "      <td>0.477024</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.435295</td>\n",
       "      <td>1.367049</td>\n",
       "      <td>0.502024</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.338028</td>\n",
       "      <td>1.290225</td>\n",
       "      <td>0.527738</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.258634</td>\n",
       "      <td>1.235726</td>\n",
       "      <td>0.538095</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.187515</td>\n",
       "      <td>1.208292</td>\n",
       "      <td>0.536310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.129313</td>\n",
       "      <td>1.163707</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.079574</td>\n",
       "      <td>1.133940</td>\n",
       "      <td>0.548095</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.029649</td>\n",
       "      <td>1.105613</td>\n",
       "      <td>0.550714</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.990441</td>\n",
       "      <td>1.068553</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.953178</td>\n",
       "      <td>1.043064</td>\n",
       "      <td>0.570119</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.924332</td>\n",
       "      <td>1.027129</td>\n",
       "      <td>0.573929</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.895229</td>\n",
       "      <td>1.013117</td>\n",
       "      <td>0.575119</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.868012</td>\n",
       "      <td>0.994821</td>\n",
       "      <td>0.586310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.841253</td>\n",
       "      <td>0.949537</td>\n",
       "      <td>0.606071</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.815734</td>\n",
       "      <td>0.935044</td>\n",
       "      <td>0.610595</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.788745</td>\n",
       "      <td>0.925553</td>\n",
       "      <td>0.614405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.767246</td>\n",
       "      <td>0.910581</td>\n",
       "      <td>0.619405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.746999</td>\n",
       "      <td>0.908988</td>\n",
       "      <td>0.620238</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.728330</td>\n",
       "      <td>0.894076</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.713440</td>\n",
       "      <td>0.876974</td>\n",
       "      <td>0.633214</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.698338</td>\n",
       "      <td>0.870070</td>\n",
       "      <td>0.638333</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.684280</td>\n",
       "      <td>0.869795</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.670193</td>\n",
       "      <td>0.868428</td>\n",
       "      <td>0.636190</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.657607</td>\n",
       "      <td>0.853097</td>\n",
       "      <td>0.648929</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.647909</td>\n",
       "      <td>0.850502</td>\n",
       "      <td>0.648452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.635040</td>\n",
       "      <td>0.847425</td>\n",
       "      <td>0.650476</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>0.845541</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.614520</td>\n",
       "      <td>0.843851</td>\n",
       "      <td>0.654524</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.605433</td>\n",
       "      <td>0.831532</td>\n",
       "      <td>0.660238</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.597401</td>\n",
       "      <td>0.835937</td>\n",
       "      <td>0.656667</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.588850</td>\n",
       "      <td>0.823753</td>\n",
       "      <td>0.662857</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.582398</td>\n",
       "      <td>0.824356</td>\n",
       "      <td>0.663095</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.571245</td>\n",
       "      <td>0.828763</td>\n",
       "      <td>0.663214</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.564515</td>\n",
       "      <td>0.822923</td>\n",
       "      <td>0.666786</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.555924</td>\n",
       "      <td>0.816941</td>\n",
       "      <td>0.669405</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df75b2-d5b4-449a-9295-073be6268985",
   "metadata": {},
   "source": [
    "Again, we have a significant improvement :).\n",
    "\n",
    "Let's add one more layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6679c035-5665-4932-ab10-4aaca5879065",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net3 = nn.Sequential(\n",
    "    nn.Linear(28*28,150),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(150,150),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(150,130),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(130,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa5d6442-6a77-47da-843e-6c42c9dbb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net3, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c06eed4e-c412-4b2b-b66d-15410cf5c40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.431557</td>\n",
       "      <td>3.259079</td>\n",
       "      <td>0.206429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.937935</td>\n",
       "      <td>2.220023</td>\n",
       "      <td>0.325952</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.019956</td>\n",
       "      <td>1.611896</td>\n",
       "      <td>0.471905</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.544070</td>\n",
       "      <td>1.360150</td>\n",
       "      <td>0.527262</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.243392</td>\n",
       "      <td>1.301756</td>\n",
       "      <td>0.541429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.087905</td>\n",
       "      <td>1.027154</td>\n",
       "      <td>0.605595</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.959080</td>\n",
       "      <td>0.913137</td>\n",
       "      <td>0.629762</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.866579</td>\n",
       "      <td>0.862369</td>\n",
       "      <td>0.635952</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.796565</td>\n",
       "      <td>0.824086</td>\n",
       "      <td>0.648810</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.717660</td>\n",
       "      <td>0.798681</td>\n",
       "      <td>0.648452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.691881</td>\n",
       "      <td>0.788316</td>\n",
       "      <td>0.645238</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.676207</td>\n",
       "      <td>0.809428</td>\n",
       "      <td>0.630357</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.611673</td>\n",
       "      <td>0.744474</td>\n",
       "      <td>0.666071</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.581864</td>\n",
       "      <td>0.747724</td>\n",
       "      <td>0.657976</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.554930</td>\n",
       "      <td>0.818501</td>\n",
       "      <td>0.609286</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.541026</td>\n",
       "      <td>0.690311</td>\n",
       "      <td>0.691548</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.498711</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>0.706905</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.472771</td>\n",
       "      <td>0.687034</td>\n",
       "      <td>0.686310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.467683</td>\n",
       "      <td>0.697886</td>\n",
       "      <td>0.681310</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.416675</td>\n",
       "      <td>0.735107</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.414598</td>\n",
       "      <td>0.633161</td>\n",
       "      <td>0.724762</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.423788</td>\n",
       "      <td>0.599057</td>\n",
       "      <td>0.758452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.373275</td>\n",
       "      <td>0.657774</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.382927</td>\n",
       "      <td>0.588648</td>\n",
       "      <td>0.764048</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.352943</td>\n",
       "      <td>0.661454</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.339068</td>\n",
       "      <td>0.570765</td>\n",
       "      <td>0.778452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.321054</td>\n",
       "      <td>0.593456</td>\n",
       "      <td>0.749048</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.310962</td>\n",
       "      <td>0.675250</td>\n",
       "      <td>0.682619</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.308901</td>\n",
       "      <td>0.568069</td>\n",
       "      <td>0.778333</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.287075</td>\n",
       "      <td>0.654701</td>\n",
       "      <td>0.697262</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.283014</td>\n",
       "      <td>0.558315</td>\n",
       "      <td>0.784167</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.246855</td>\n",
       "      <td>0.616527</td>\n",
       "      <td>0.726429</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.251485</td>\n",
       "      <td>0.606696</td>\n",
       "      <td>0.733214</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.252415</td>\n",
       "      <td>0.554635</td>\n",
       "      <td>0.788929</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.234156</td>\n",
       "      <td>0.626686</td>\n",
       "      <td>0.717143</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.241172</td>\n",
       "      <td>0.551182</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.223509</td>\n",
       "      <td>0.599659</td>\n",
       "      <td>0.740833</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.219075</td>\n",
       "      <td>0.543459</td>\n",
       "      <td>0.803929</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.206035</td>\n",
       "      <td>0.568478</td>\n",
       "      <td>0.774048</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.198833</td>\n",
       "      <td>0.587311</td>\n",
       "      <td>0.753095</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ba27a-f996-4b61-8b77-18f38b3d3afe",
   "metadata": {},
   "source": [
    "Another significant improvement, but we start to see that the accuracy does not constantly go up, but it also goes down. I suspect that this can be fixed by adjusting the learning rate.\n",
    "\n",
    "Let's add one more layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dfd74c54-5a12-4956-a080-1ac8046a3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net4 = nn.Sequential(\n",
    "    nn.Linear(28*28,150),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(150,150),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(150,150),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(150,130),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(130,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4920bd3b-cfe7-44b5-9cd7-a6d82da4c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net4, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1368e136-79e7-424d-b7b0-7c6dcd0663e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.584154</td>\n",
       "      <td>3.168080</td>\n",
       "      <td>0.208214</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.669653</td>\n",
       "      <td>2.105103</td>\n",
       "      <td>0.346071</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.799561</td>\n",
       "      <td>1.497062</td>\n",
       "      <td>0.427262</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.362472</td>\n",
       "      <td>1.169315</td>\n",
       "      <td>0.570595</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.116101</td>\n",
       "      <td>0.982570</td>\n",
       "      <td>0.616905</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.942988</td>\n",
       "      <td>0.886795</td>\n",
       "      <td>0.653929</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.831714</td>\n",
       "      <td>0.824128</td>\n",
       "      <td>0.669048</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.736036</td>\n",
       "      <td>0.770736</td>\n",
       "      <td>0.690595</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.663777</td>\n",
       "      <td>0.742197</td>\n",
       "      <td>0.695476</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.618736</td>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.681667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.533205</td>\n",
       "      <td>0.741921</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.503085</td>\n",
       "      <td>0.650247</td>\n",
       "      <td>0.748571</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.456369</td>\n",
       "      <td>0.676429</td>\n",
       "      <td>0.705119</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.413309</td>\n",
       "      <td>0.635177</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.411717</td>\n",
       "      <td>0.601080</td>\n",
       "      <td>0.774048</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.349024</td>\n",
       "      <td>0.610258</td>\n",
       "      <td>0.752976</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.340945</td>\n",
       "      <td>0.589349</td>\n",
       "      <td>0.773690</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.321726</td>\n",
       "      <td>0.597532</td>\n",
       "      <td>0.753690</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.303592</td>\n",
       "      <td>0.556267</td>\n",
       "      <td>0.806905</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.276728</td>\n",
       "      <td>0.585406</td>\n",
       "      <td>0.756548</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.250896</td>\n",
       "      <td>0.535308</td>\n",
       "      <td>0.811190</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.241036</td>\n",
       "      <td>0.529699</td>\n",
       "      <td>0.816190</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.232675</td>\n",
       "      <td>0.567625</td>\n",
       "      <td>0.765595</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.245956</td>\n",
       "      <td>0.520769</td>\n",
       "      <td>0.826786</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.222691</td>\n",
       "      <td>0.528771</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.212597</td>\n",
       "      <td>0.507429</td>\n",
       "      <td>0.831309</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.182313</td>\n",
       "      <td>0.513811</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.199865</td>\n",
       "      <td>0.506157</td>\n",
       "      <td>0.831429</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.181104</td>\n",
       "      <td>0.498714</td>\n",
       "      <td>0.840119</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.159723</td>\n",
       "      <td>0.504569</td>\n",
       "      <td>0.831548</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.171665</td>\n",
       "      <td>0.498971</td>\n",
       "      <td>0.838333</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.494560</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.150133</td>\n",
       "      <td>0.505995</td>\n",
       "      <td>0.831309</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.144127</td>\n",
       "      <td>0.491928</td>\n",
       "      <td>0.850476</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.134267</td>\n",
       "      <td>0.503205</td>\n",
       "      <td>0.833571</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.130969</td>\n",
       "      <td>0.483974</td>\n",
       "      <td>0.854524</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.118195</td>\n",
       "      <td>0.493375</td>\n",
       "      <td>0.845833</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.108849</td>\n",
       "      <td>0.486641</td>\n",
       "      <td>0.853095</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.110277</td>\n",
       "      <td>0.486275</td>\n",
       "      <td>0.854762</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>0.502901</td>\n",
       "      <td>0.837381</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2006db9-c682-491f-9d84-f3aa728af947",
   "metadata": {},
   "source": [
    "Again, a good improvement, but the results oscillate more between epochs, something to look into. But for now, let's switch the perspective to complete the whole game, let's move on to doing the predictions of the test data.\n",
    "\n",
    "Before we do that, something odd I was not able to solve: Somehow I could not export the model: Any idea why that is the case of how to fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61ffc228-3706-4a17-b551-ea5451c0825d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('.')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "806556a8-e8c3-4c49-b6d6-106a792c285c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'export.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;34m'pickle'\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m'/home/chrwittm/mambaforge/lib/python3.10/pickle.py'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Export the content of `self` without the items and the optimizer state for inference\n",
       "\u001b[0;31mFile:\u001b[0m      ~/mambaforge/lib/python3.10/site-packages/fastai/learner.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.export?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "137ca326-d978-400c-8d4f-5e67b16ded7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3eae05-9410-4d9f-8cf8-bcf110c92383",
   "metadata": {},
   "source": [
    "If executed, the above cell results in\n",
    "\n",
    "```\n",
    "AttributeError: 'list' object has no attribute 'new_empty'\n",
    "```\n",
    "\n",
    "Any ideas how to fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a51cb-90bc-40e4-8142-87ab955f3aaf",
   "metadata": {},
   "source": [
    "## Predictions of the test data\n",
    "\n",
    "Let's use our trained model to create a submission for the kaggle competition - knowing that the result could easily be improved, but this is about playing the whole game.\n",
    "\n",
    "### Loading test data\n",
    "\n",
    "First, we need to load the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2c1cde26-d292-4bef-a8b7-b645cfadc3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb2c9b-693d-416f-b69b-e714544a68d4",
   "metadata": {},
   "source": [
    "### Failure mode: Cannot run `learn.predict`\n",
    "\n",
    "Again, an unsolved mystery: I could not work out how to call `learn.predict` to get the predictions, also other attempts failed.\n",
    "\n",
    "Let me document my attempts before moving on to a method which worked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3cbfb2-b977-48ec-ad70-15411f1ce0f1",
   "metadata": {},
   "source": [
    "Just to make sure that we know what we want to predict, here is a digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08e04f97-bf24-4a58-b811-c225754ecbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil2fast2(pil):\n",
    "    return PILImage.create(np.array(pil.convert('RGB')))\n",
    "\n",
    "def get_fast_test_image(index):\n",
    "    im = torch.tensor(test.iloc[index])\n",
    "    pil = Image.frombytes('L', (28, 28), bytes(im))#.convert('RGB')\n",
    "    fast = pil2fast2(pil)\n",
    "    return fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd3b45cc-87b5-41bd-bcd7-7cc494f6a146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB30lEQVR4nO2UvcriQBSG51sXBYWIP42FIAgaBEVQC8H/QrDzHuyiYGGwyAXYeAUWSm5ALay1ELQQBhtTSbQxChbiQBQxGLcIO+vnxuwattvvqSbvOeedc2bCAPDFv+ZDO2w2m00mE/7MZDKlUgkAUK1WeZ7XuWez2bypEQ6HdTomEonNZqNqOp/PJ5NJKBR625TjOFVHzHq9jkaj75nmcrndboctKpUKSZIkSdZqNVEUFbHRaBgMhqfCP1xUOp2ORCLKejAYLJdLZQ0hxMdqt9sRQu/1q0o8HscTWK3Wp+g3fabarek0jcVi+gq1gBBqjP/9byySyaTP57vdbizLAgCCwaDD4VBC0+lUkqSnfJXbt1gsBEEUi8X9fk9RFADA7/e7XC5ZlsfjMQDA7XZ7vV4AAMdxhUJBEAStjgKBAE3T3W5X+5/H8DxP0/Tj46BCvV5/rDmdTovFYrVaaVuzLPv7sf5ClmWcOhwOlQfJ4/HMZjOsH49HhmEYhhmNRljs9XovTe/3O847HA6rnyCEFHG73ebzeSXZZrP1+31BEJTQS9NOp/NqRgghRVHZbPapJJVKiaLYbrcfxU+3bzQanU5nq9V6FMvlMkJIkqTz+azaCkEQl8vler2+bPaL/4kfT+Gu5NolgqMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "PILImage mode=RGB size=28x28"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_digit = get_fast_test_image(0)\n",
    "fast_digit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f662a-9cf4-4331-b9c4-7c4aa519b2e8",
   "metadata": {},
   "source": [
    "Getting the same as a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "847c66e5-8aeb-405e-8aab-7e9e1cd798ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_image_as_tensor(index):\n",
    "    digit = torch.tensor((test.iloc[index])/255).float()\n",
    "    digit = digit.view(len(digit), 1)\n",
    "    return digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1a922532-87f7-4365-ad14-bcd98f502d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digit = get_test_image_as_tensor(0)\n",
    "test_digit.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08350771-7dc2-4d71-bb97-f0f356433ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.predict(test_digit.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71da49c-8f20-4ca9-adec-1ba66a41cd56",
   "metadata": {},
   "source": [
    "The above cell fails with\n",
    "\n",
    "```\n",
    "AttributeError: 'list' object has no attribute 'decode_batch'\n",
    "```\n",
    "\n",
    "Any idea why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4413891-df2c-466f-b332-b41cad6fa7d9",
   "metadata": {},
   "source": [
    "Alternative approach which a new test data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0a10cf47-16fa-4a65-ba4a-31fddf5900b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28000, 784])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = torch.tensor((test.iloc[:,:].values)/255).float()\n",
    "test_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4548c371-d198-4f6e-b8a2-01ea47a7cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test_dl(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90808d34-874c-4cac-bc7c-390c7b51424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b47e6-c067-4c65-9534-83fed6f77c02",
   "metadata": {},
   "source": [
    "The above fails with\n",
    "\n",
    "```\n",
    "TypeError: Sequential.forward() takes 2 positional arguments but 256 were given\n",
    "```\n",
    "\n",
    "Any ideas why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e0886-a4df-4ce5-8f73-db827aa2b907",
   "metadata": {},
   "source": [
    "Note: calling `learn.get_preds()` returns the predictions of the validation set, so how to I get it to run on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a358294-ff43-4fbc-ad3a-06732be63da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds,targs = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d2ccae13-0502-493b-8be9-0e496d310e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8400"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "49279ac1-ce0a-4f58-8238-d60c4b32ddc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0621],\n",
       "        [7.2984],\n",
       "        [6.9915],\n",
       "        ...,\n",
       "        [7.1430],\n",
       "        [6.1489],\n",
       "        [8.5495]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdef216-5e2d-4694-b752-3ac4d6e73889",
   "metadata": {},
   "source": [
    "### Solution: Just call the forward pass\n",
    "\n",
    "After trying the above I took a break, and while driving to the store for grocery shopping it suddenly occurred to me that it should be quite simple to make the predictions without the learner, you just need to call the forward pass of the trained model. And indeed, there is a `.forward()`-method :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9a98cc3d-5d48-4310-99f4-f9290e2590e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8600]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_net4.forward(test_digit.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aaed53-a439-43e0-9aec-8ab36e39d2ca",
   "metadata": {},
   "source": [
    "Indeed, our test digit is a 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "88d4aa5e-d47e-40d0-aaa7-d712cb87f156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB30lEQVR4nO2UvcriQBSG51sXBYWIP42FIAgaBEVQC8H/QrDzHuyiYGGwyAXYeAUWSm5ALay1ELQQBhtTSbQxChbiQBQxGLcIO+vnxuwattvvqSbvOeedc2bCAPDFv+ZDO2w2m00mE/7MZDKlUgkAUK1WeZ7XuWez2bypEQ6HdTomEonNZqNqOp/PJ5NJKBR625TjOFVHzHq9jkaj75nmcrndboctKpUKSZIkSdZqNVEUFbHRaBgMhqfCP1xUOp2ORCLKejAYLJdLZQ0hxMdqt9sRQu/1q0o8HscTWK3Wp+g3fabarek0jcVi+gq1gBBqjP/9byySyaTP57vdbizLAgCCwaDD4VBC0+lUkqSnfJXbt1gsBEEUi8X9fk9RFADA7/e7XC5ZlsfjMQDA7XZ7vV4AAMdxhUJBEAStjgKBAE3T3W5X+5/H8DxP0/Tj46BCvV5/rDmdTovFYrVaaVuzLPv7sf5ClmWcOhwOlQfJ4/HMZjOsH49HhmEYhhmNRljs9XovTe/3O847HA6rnyCEFHG73ebzeSXZZrP1+31BEJTQS9NOp/NqRgghRVHZbPapJJVKiaLYbrcfxU+3bzQanU5nq9V6FMvlMkJIkqTz+azaCkEQl8vler2+bPaL/4kfT+Gu5NolgqMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "PILImage mode=RGB size=28x28"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_digit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298cafca-72b2-4a3c-beed-51f18cd4830c",
   "metadata": {},
   "source": [
    "So let's run that on the whole dataset by simply passing the whole data, rounding and converting to integer to get the right format for submitting to kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc98a194-2885-4d9c-8af2-ef6d3f5ef44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = simple_net4.forward(test_x).round().int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf386830-77dd-4178-a89e-e56438dee3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5af1b07-1a4b-4489-8e6b-4df4c0a2ab0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [0],\n",
       "        [9],\n",
       "        ...,\n",
       "        [3],\n",
       "        [9],\n",
       "        [2]], dtype=torch.int32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd6c65-ed02-4c3e-bdab-dfdaf670d917",
   "metadata": {},
   "source": [
    "As a final step, let's create the `csv`-file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4f0f1aa7-2fa9-4cb3-9baf-957be7ff504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns=['ImageId', 'Label'])\n",
    "submission['ImageId'] = range(1,len(test_preds)+1)\n",
    "submission['Label'] = test_preds.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "64fc00f6-cef7-4596-a910-1d3db84c355e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      3\n",
       "4        5      3"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ded89-7d67-4e83-806b-48e8880d245b",
   "metadata": {},
   "source": [
    "Downloading the `csv`-file: (commented not to have a new version each time I run the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "267b9148-b19a-46a6-aea7-0fae3659599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv('submission_simple_net4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dc71aa-54a3-4c6e-abcd-d991966f58e6",
   "metadata": {},
   "source": [
    "The submission turned out as expected with a similar accuracy as indicated by our validation set.\n",
    "\n",
    "Not a perfect submission result, but great learnings along the way :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4efdd-92f3-4a09-82e9-4584b14db820",
   "metadata": {},
   "source": [
    "![My third submission result](sub3-084817.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
